{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Counting and Classification\n",
    "<i> Innovation Lab Project WiSe 2020/21 by Laurence-Sebastian Alscher, Mohammed Goha and Maria Kaltenbrunner </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "We are classifying cars and motorbikes on images with a model pretrained using the YOLO algorithm.\n",
    "\n",
    "The YOLO algorithm divides each image into a grid of size GxG, then applying a classification algorithm on each grid cell.\n",
    "An object is detected in the grid cell where the center of its bounding box lies. In case there might be more than one object in a grid cell, anchor boxes can be specified to be able to find more than one bounding box.\n",
    "\n",
    "If anchor boxes A are specified, the algorithm looks for one of each specified anchor boxes in the grid cell.\n",
    "\n",
    "Each bounding box B is given as a list of five values (x, y, w, h, confidence).\n",
    "The (x, y) corrdinates give the center of the box relative to the location of the grid cell. The (w,h) dimensions represent the box dimension. All four values are normalized to [0,1].\n",
    "The confidence is a probability which represents how sure the model is that there is any object in this grid cell.\n",
    "\n",
    "The probability of an object to be of a certain class is computed if the grid cell probably contains any object. The class predictions P are a list of probabilites for each looked for class (p1, p2, p3, ...).\n",
    "\n",
    "Since the bounding boxes are looked for in each grid cell, the YOLO Algorithm returns a tensor of G x G x A x (B + P).\n",
    "Therefore in a grid of 19x19 with 5 anchor boxes and 2 classes to be predicted, the tensor returned by the algorithm would be of shape (19, 19, 5, 7).\n",
    "\n",
    "### Hard Facts\n",
    "We are trying to detect 2 classes (cars and motorbikes) using 5 anchor boxes per grid cell.\n",
    "Since the model is trained to predict 80 different classes, the expected output must deal with these 80 class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolo_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b37bd020f89d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myolo_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscale_boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yolo_utils'"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to filter the bounding boxes by threshold on class scores\n",
    "The YOLO algorithm returns a massive tensor. A first filtering is done using a threshold on class scores, therefore removing all boxes which have a very low probability of showing any of the objects looked for. <br>\n",
    "<br>Step 1: The class probabilities represent how likely each of the classes are correct for this box GIVEN that there is any object. To get a more absolute score of the classes being in the image we compute a score of these two arguments.\n",
    "<br>Step 2: The highest score for each grid cell has to be found out to decide whether it is under the threshold. For that, the maximum of the last axis is taken by the Keras max() function and its index found by the Keras argmax() function.\n",
    "<br>Step 3: To return only the boxes we want to keep, we first have to check which of the maximum scores holds up to the threshold. We therefore create a mask, which we can later use on the boxes to know which to return.\n",
    "<br>Step 4: By appling the mask to the tensors, we find our wanted filtered boxes, the highest class score for each box and the class that is probably depicted in that box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(boxes, confidence, class_probs, threshold = 0.6):\n",
    "    \"\"\"\n",
    "    Filters the bounding boxes based on their probabilities and a certain threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    boxes -- tensor of shape (19, 19, 5, 4), coordinates and dimensions of each box in each grid cell\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1), confidence for each box in each grid cell\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80), probabilities for each class for each box in each grid cell\n",
    "    threshold -- float, if no class probability of a box is higher than threshold the box will be removed\n",
    "    \n",
    "    Returns:\n",
    "    final_scores -- tensor of shape (None,), containing the score of class probability for each box chosen\n",
    "    final_boxes -- tensor of shape (None,4), containing the coordinates of each box chosen\n",
    "    final_classes -- tensor of shape (None,), containing the index of the most probable class for each box chosen\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Compute a score for each box\n",
    "    scores = np.multiply(confidence, class_probs)\n",
    "    \n",
    "    # Step 2: Find the highest score and its corresponding index for each box\n",
    "    class_scores = K.max(scores, axis=-1)\n",
    "    classes = K.argmax(scores, axis=-1)\n",
    "    \n",
    "    # Step 3: Create a mask to filter the boxes based on the threshold\n",
    "    filtering_mask = K.greater_equal(class_scores, threshold)\n",
    "    \n",
    "    # Step 4: Apply the mask to the scores, boxes and classes\n",
    "    # Find the scores of the boxes which we want to keep\n",
    "    final_scores = tf.boolean_mask(class_scores, filtering_mask)\n",
    "    # Find the boxes we want to keep\n",
    "    final_boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    # Find the classes of the boxes we want to keep\n",
    "    final_classes = tf.boolean_mask(classes, filtering_mask)\n",
    "    \n",
    "    # Return the three tensors with the data of the filtered boxes\n",
    "    return final_scores, final_boxes, final_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4)\n",
      "scores[2] = 10.750582\n",
      "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
      "classes[2] = 7\n",
      "scores.shape = (?,)\n",
      "boxes.shape = (?, 4)\n",
      "classes.shape = (?,)\n"
     ]
    }
   ],
   "source": [
    "# Test the filter boxes function\n",
    "# Test code taken from Autonomous Driving - Car detection (see links below)\n",
    "with tf.Session() as test_a:\n",
    "    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = filter_boxes(boxes, box_confidence, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to filter intersection over union\n",
    "\n",
    "This function is generally used in object detection, independent of the model used.\n",
    "It uses basic functionality of set theory to evaluate how similar two boxes are,\n",
    "therefore if one of the boxes is the actual, right one it can determine how\n",
    "well the prediction worked. It is also used to later filter out from the predicted boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculates the intersection over union of the actual (given) bounding box and the predicted bounding box \n",
    "    to be able to evaluate the predicted result.\n",
    "    If the intersection over union is greater than a certain threshold, it is considered good enough.\n",
    "    \n",
    "    The parameters are the two boxes to be compared, their order doesn't influence the result.\n",
    "    Parameters:\n",
    "    box1 -- list object with coordinates (x1, y1, x2, y2)\n",
    "    box2 -- list object with coordinates (x1, y1, x2, y2)\n",
    "    \n",
    "    Returns:\n",
    "    iou -- float, the computed intersection over union of the two boxes given\n",
    "    \"\"\"\n",
    "    # To get the coordinates of the intersection\n",
    "    # Looking for the maximum to get the upper border and for the minimum to get the lower border\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    # Compute the area of the intersection\n",
    "    intersection = (x2-x1) * (y2-y1)\n",
    "    \n",
    "    # Compute the area of the union\n",
    "    # Rule for computing the union of two sets knowing the intersection: Union(A,B) = A + B - Intersection(A,B)\n",
    "    box1_area = (box1[3] - box1[1])*(box1[2] - box1[0])\n",
    "    box2_area = (box2[3] - box2[1])*(box2[2] - box2[0])\n",
    "    union = (box1_area + box2_area) - intersection\n",
    "    \n",
    "    # Compute the intersection over union\n",
    "    iou = intersection/union\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intersection over union of our two boxes is 0.2222222222222222\n",
      "Are the results the same when given the boxes in different order? True\n"
     ]
    }
   ],
   "source": [
    "# Test the IoU function\n",
    "box1 = (4, 2, 8, 6)\n",
    "box2 = (2, 4, 9, 8)\n",
    "\n",
    "print(\"The intersection over union of our two boxes is\", intersection_over_union(box1, box2))\n",
    "\n",
    "# We can also show that the order of the boxes given as arguments doesn't matter\n",
    "print(\"Are the results the same when given the boxes in different order?\", intersection_over_union(box1, box2) == intersection_over_union(box2, box1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to filter the bounding boxes by non-max-suppression (using intersection over union)\n",
    "For each object more than one possible bounding box may be detected. To find out the one of these which best focuses on the object and to suppress the remaining ones, this function first takes the box with the highest score (computed in the filter function), computes the intersection over union of this box with the other boxes and then suppresses those of the other boxes, which have a iou with it above a certain threshold. Therefore, the most confident box remains while all boxes which probably mark the same object (but with less confidence) are removed. \n",
    "<br>For this function we use a built-in tensorflow function to reduce complexity. Therefore the main object is to prepare the right parameters for the built-in function and later filter our boxes, classes and scores based on the indices returned by that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(scores, boxes, classes, max_boxes = 10, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Results in only one box per object by choosing the box with the highest probability,\n",
    "    suppressing all boxes which have a high intersection over union with this box (which are similar).\n",
    "    This function uses the tensorflow non max suppression method.\n",
    "    \n",
    "    Parameters:\n",
    "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() \n",
    "    classes -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    max_boxes -- integer, the maximum number of boxes wanted\n",
    "    iou_threshold -- float, the threshold for the iou result\n",
    "    \n",
    "    Returns:\n",
    "    new_scores -- tensor of shape(max_boxes,), filtered scores by indices from tensorflow non max suppression\n",
    "    new_boxes -- tensor of shape(max_boxes, 4), filtered boxes by indices from tensorflow non max suppression\n",
    "    new_classes -- tensor of shape(max_boxes,), filtered classes by indices from tensorflow non max suppression\n",
    "    \"\"\"\n",
    "    # The tensorflow non max suppression method takes as a parameter the max_output_size, \n",
    "    # which is an integer tensor representing the maximum number of boxes to be selected.\n",
    "    # We create a tensor with the dimensions of our parameter to give to the tensorflow method\n",
    "    max_output_size = K.variable(max_boxes, dtype=\"int32\")\n",
    "    # Initialize the variable to use it later in a tensorflow method\n",
    "    K.get_session().run(tf.variables_initializer([max_output_size]))\n",
    "    \n",
    "    # Use the non_max_suppression method available in tensorflow to get the indices of the boxes to keep\n",
    "    # This function returns the indices as a tensor\n",
    "    indices = tf.image.non_max_suppression(boxes, scores, max_output_size, threshold)\n",
    "    \n",
    "    # Since the indices are held in a tensor, we use the Keras gather method to filter \n",
    "    new_scores = K.gather(scores, indices)\n",
    "    new_boxes = K.gather(boxes, indices)\n",
    "    new_classes = K.gather(classes, indices)\n",
    "    \n",
    "    return new_scores, new_boxes, new_classes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 6.938395\n",
      "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
      "classes[2] = -2.2452729\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test_b:\n",
    "    scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert between representations of boxes\n",
    "This function is kindly borrowed from YAD2K (see below).\n",
    "\n",
    "The YOLO model returns the boxes represented via their midpoint (box_xy) and their width (box_wh).\n",
    "In our filter functions we work with a representation using the corners, therefore it is necessary to convert the boxes representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kindly borrow from YAD2K keras_yolo.py\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to scale boxes to the original image size\n",
    "This function is kindly borrow from deeplearning.ai (see below).\n",
    "\n",
    "The YOLO model is trained top work on images of 608x608, therefore when the boxes are returned we need to rescale the boxes so they can be shown on the original test image we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kindly borrowed from deeplearning.ai yolo_utils.py\n",
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function which combines all the filter functions above\n",
    "The functions above have to be called on the output of the model to filter the returned boxes.\n",
    "Since the YOLO model is expecting images of shape 608x608, it is useful here to rescale the boxes so they can be shown on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(yolo_outputs, image_shape=(720., 1280.), max_boxes=10, score_threshold=0.6, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Filters the output of the YOLO model to the boxes that are most likely good predictions \n",
    "    based on the functions we have implemented above.\n",
    "    \n",
    "    Parameters:\n",
    "    yolo_outputs -- the output of the yolo model, contains 4 variables:\n",
    "                    box_confidence -- tensor of shape (None, 19, 19, 5, 1)\n",
    "                    box_xy -- tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_wh -- tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_class_probs -- tensor of shape (None, 19, 19, 5, 80)\n",
    "    image_shape -- float32 tensor of shape (2,), containing the shape of the inputted images\n",
    "    max_boxes -- integer, maximum number of boxes we want to keep\n",
    "    score_threshold -- float, value by which boxes are filtered base on the class probability score\n",
    "    iou_threshold -- float, value by which boxes are considered too much overlapping \n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), filtered scores for each box chosen\n",
    "    boxes -- tensor of shape (None, 4), filtered box coordinates chosen\n",
    "    classes -- tensor of shape (None,), filtered class for each box chosen\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack the output of the YOLO model\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    \n",
    "    # Use the box conversion function seen above to convert the representation of the boxes\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    # Filter the boxes based on a threshold of scores\n",
    "    scores, boxes, classes = filter_boxes(boxes, box_confidence, class_probs, score_threshold)\n",
    "    \n",
    "    # Scale the boxes to the original image shape so they can be meaningfully shown in the original images\n",
    "    boxes = scale_boxes(boxes, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_b:\n",
    "    yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Object detection and classification with a YOLO pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen\n",
    "* [Intersection over Union (IoU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)\n",
    "* [Hackernoon - Understanding YOLO](https://hackernoon.com/understanding-yolo-f5a74bbc7967)\n",
    "* [YOLO Filter Boxes Walkthrough](https://mc.ai/yolo-filter-boxes-walkthrough/)\n",
    "* [Autonomous Driving - Car detection](https://github.com/enggen/Deep-Learning-Coursera/blob/master/Convolutional%20Neural%20Networks/Week3/Car%20detection%20for%20Autonomous%20Driving/Autonomous%20driving%20application%20-%20Car%20detection%20-%20v1.ipynb)\n",
    "* [(Faster) Non-Maximum Suppression Python](https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/)\n",
    "* [A Practical Guide to Object Detection using the YOLO Framework](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/)\n",
    "* [Tensorflow Non Max Suppression (Documentation)](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression)\n",
    "* [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)\n",
    "* [YAD2K keras_yolo.py](https://github.com/allanzelener/YAD2K/blob/master/yad2k/models/keras_yolo.py)\n",
    "* [Deeplearning.ai](https://github.com/JudasDie/deeplearning.ai)\n",
    "* [Deeplearning.ai yolo_utils.py](https://github.com/JudasDie/deeplearning.ai/blob/master/Convolutional%20Neural%20Networks/week3/yolo_utils.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
